{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhxzhZalW0gG"
      },
      "source": [
        "# Part 3: Evaluation & Debugging\n",
        "\n",
        "In this notebook, we'll learn how to:\n",
        "\n",
        "1. **Evaluate** RAG quality with test cases\n",
        "2. **Debug** when things go wrong\n",
        "3. **Improve** based on failures\n",
        "\n",
        "A system is only as good as your ability to measure and fix it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYaaW4VEW0gH"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "COOWNs3UW0gI",
        "outputId": "edc8ba20-f852-477c-c918-d41ab0745105",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/workshop\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/i33ym/workshop.git 2>/dev/null || echo \"Already cloned\"\n",
        "%cd workshop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "k-7CixufW0gK",
        "outputId": "7e0be818-1fa7-4cec-8ea0-0d80a42f37de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/67.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m84.6/84.6 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m51.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.7/21.7 MB\u001b[0m \u001b[31m89.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m78.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m476.0/476.0 kB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m94.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m132.6/132.6 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m220.0/220.0 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m517.7/517.7 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m128.4/128.4 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m97.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m456.8/456.8 kB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "google-adk 1.20.0 requires opentelemetry-api<=1.37.0,>=1.37.0, but you have opentelemetry-api 1.39.1 which is incompatible.\n",
            "google-adk 1.20.0 requires opentelemetry-sdk<=1.37.0,>=1.37.0, but you have opentelemetry-sdk 1.39.1 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-exporter-otlp-proto-common==1.37.0, but you have opentelemetry-exporter-otlp-proto-common 1.39.1 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-proto==1.37.0, but you have opentelemetry-proto 1.39.1 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-sdk~=1.37.0, but you have opentelemetry-sdk 1.39.1 which is incompatible.\n",
            "opentelemetry-exporter-gcp-logging 1.11.0a0 requires opentelemetry-sdk<1.39.0,>=1.35.0, but you have opentelemetry-sdk 1.39.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q openai langchain langchain-openai langchain-community langchain-text-splitters chromadb rank-bm25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vW_P5JCaW0gK",
        "outputId": "ae716239-9712-4b85-ebc2-04c2ba183c68",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your OpenAI API key: Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter your OpenAI API key: \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "BVkOjB6ZW0gM",
        "outputId": "6f34dc7a-3e9a-4507-ea80-5d4e07a8e34c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 679 chunks\n"
          ]
        }
      ],
      "source": [
        "# Load everything from Part 2\n",
        "from langchain_community.document_loaders import DirectoryLoader, TextLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_community.retrievers import BM25Retriever\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# Load and prepare\n",
        "loader = DirectoryLoader(\"docs/\", glob=\"**/*.md\", loader_cls=TextLoader)\n",
        "documents = loader.load()\n",
        "\n",
        "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "chunks = splitter.split_documents(documents)\n",
        "\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
        "vector_store = Chroma.from_documents(documents=chunks, embedding=embeddings)\n",
        "bm25_retriever = BM25Retriever.from_documents(chunks)\n",
        "bm25_retriever.k = 5\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "\n",
        "print(f\"Loaded {len(chunks)} chunks\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "gj7JXCUeW0gN",
        "outputId": "a4932e3b-6a66-4f99-c58e-0a319acdb066",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pipeline functions loaded.\n"
          ]
        }
      ],
      "source": [
        "# Copy the pipeline functions from Part 2\n",
        "\n",
        "def hybrid_search(query, k=5):\n",
        "    vector_results = vector_store.similarity_search(query, k=k)\n",
        "    bm25_results = bm25_retriever.invoke(query)[:k]\n",
        "\n",
        "    rrf_scores = {}\n",
        "    k_constant = 60\n",
        "\n",
        "    for rank, doc in enumerate(vector_results):\n",
        "        doc_id = doc.page_content[:100]\n",
        "        rrf_scores[doc_id] = rrf_scores.get(doc_id, 0) + 1 / (k_constant + rank + 1)\n",
        "        rrf_scores[doc_id + \"_doc\"] = doc\n",
        "\n",
        "    for rank, doc in enumerate(bm25_results):\n",
        "        doc_id = doc.page_content[:100]\n",
        "        rrf_scores[doc_id] = rrf_scores.get(doc_id, 0) + 1 / (k_constant + rank + 1)\n",
        "        rrf_scores[doc_id + \"_doc\"] = doc\n",
        "\n",
        "    sorted_ids = sorted(\n",
        "        [k for k in rrf_scores.keys() if not k.endswith(\"_doc\")],\n",
        "        key=lambda x: rrf_scores[x], reverse=True\n",
        "    )\n",
        "\n",
        "    results = [rrf_scores[doc_id + \"_doc\"] for doc_id in sorted_ids[:k]]\n",
        "    scores = [rrf_scores[doc_id] for doc_id in sorted_ids[:k]]\n",
        "    return results, scores\n",
        "\n",
        "def rerank_documents(query, documents, top_n=3):\n",
        "    rerank_prompt = ChatPromptTemplate.from_template(\n",
        "        \"Rate relevance 0-10. Reply with only a number.\\n\\nQuestion: {question}\\n\\nDocument: {document}\\n\\nScore:\"\n",
        "    )\n",
        "    chain = rerank_prompt | llm | StrOutputParser()\n",
        "\n",
        "    scored = []\n",
        "    for doc in documents:\n",
        "        try:\n",
        "            score = float(chain.invoke({\"question\": query, \"document\": doc.page_content[:500]}).strip())\n",
        "        except:\n",
        "            score = 5.0\n",
        "        scored.append((doc, score))\n",
        "\n",
        "    scored.sort(key=lambda x: x[1], reverse=True)\n",
        "    return scored[:top_n]\n",
        "\n",
        "def check_relevance(query, documents):\n",
        "    context = \"\\n\\n\".join([doc.page_content[:300] for doc in documents])\n",
        "    prompt = ChatPromptTemplate.from_template(\n",
        "        \"Can this context answer the question? Reply 'yes' or 'no'.\\n\\nQuestion: {question}\\n\\nContext: {context}\"\n",
        "    )\n",
        "    result = (prompt | llm | StrOutputParser()).invoke({\"question\": query, \"context\": context})\n",
        "    return \"yes\" in result.lower()\n",
        "\n",
        "def generate_answer(query, documents):\n",
        "    context = \"\\n\\n---\\n\\n\".join([doc.page_content for doc in documents])\n",
        "    prompt = ChatPromptTemplate.from_template(\n",
        "        \"Answer based only on context. If unsure, say so.\\n\\nContext:\\n{context}\\n\\nQuestion: {question}\\n\\nAnswer:\"\n",
        "    )\n",
        "    return (prompt | llm | StrOutputParser()).invoke({\"context\": context, \"question\": query})\n",
        "\n",
        "def check_grounding(answer, documents):\n",
        "    context = \"\\n\\n\".join([doc.page_content for doc in documents])\n",
        "    prompt = ChatPromptTemplate.from_template(\n",
        "        \"Is this answer supported by context? Reply 'yes' or 'no'.\\n\\nContext:\\n{context}\\n\\nAnswer: {answer}\"\n",
        "    )\n",
        "    result = (prompt | llm | StrOutputParser()).invoke({\"context\": context, \"answer\": answer})\n",
        "    return \"yes\" in result.lower()\n",
        "\n",
        "print(\"Pipeline functions loaded.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OoOU6QH9W0gN"
      },
      "source": [
        "## Creating a Test Dataset\n",
        "\n",
        "To evaluate RAG, you need:\n",
        "1. **Questions** â€” what users might ask\n",
        "2. **Expected answers** â€” what the correct response should contain\n",
        "\n",
        "This is called a \"golden dataset\" or \"ground truth\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Lq6y5HHFW0gO",
        "outputId": "31a137e7-f172-4b33-9974-dbd62d334c98",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created 5 test cases\n"
          ]
        }
      ],
      "source": [
        "# Define test cases\n",
        "test_cases = [\n",
        "    {\n",
        "        \"question\": \"How do I authenticate API requests?\",\n",
        "        \"expected_keywords\": [\"token\", \"authorization\", \"header\"],\n",
        "        \"should_answer\": True\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"What is the endpoint for creating a payment?\",\n",
        "        \"expected_keywords\": [\"POST\", \"payment\", \"api\"],\n",
        "        \"should_answer\": True\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"What error codes can the API return?\",\n",
        "        \"expected_keywords\": [\"error\", \"code\", \"400\", \"401\", \"500\"],\n",
        "        \"should_answer\": True\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"How do I integrate with Stripe?\",\n",
        "        \"expected_keywords\": [],\n",
        "        \"should_answer\": False  # Not in our docs!\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"What is the meaning of life?\",\n",
        "        \"expected_keywords\": [],\n",
        "        \"should_answer\": False  # Completely off-topic\n",
        "    }\n",
        "]\n",
        "\n",
        "print(f\"Created {len(test_cases)} test cases\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TikFT6CVW0gP"
      },
      "source": [
        "## Evaluation Metrics\n",
        "\n",
        "We'll measure three things:\n",
        "\n",
        "1. **Retrieval Quality** â€” Did we find relevant documents?\n",
        "2. **Answer Quality** â€” Does the answer contain expected information?\n",
        "3. **Appropriate Refusal** â€” Did we correctly say \"I don't know\" when needed?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "nySNIkj7W0gQ"
      },
      "outputs": [],
      "source": [
        "def evaluate_answer(answer, test_case):\n",
        "    \"\"\"Evaluate a single answer against a test case.\"\"\"\n",
        "\n",
        "    result = {\n",
        "        \"question\": test_case[\"question\"],\n",
        "        \"answer\": answer[:200],\n",
        "        \"metrics\": {}\n",
        "    }\n",
        "\n",
        "    # Check if answer contains expected keywords\n",
        "    answer_lower = answer.lower()\n",
        "\n",
        "    if test_case[\"should_answer\"]:\n",
        "        # Should provide an answer with keywords\n",
        "        keywords_found = sum(1 for kw in test_case[\"expected_keywords\"] if kw.lower() in answer_lower)\n",
        "        keywords_total = len(test_case[\"expected_keywords\"])\n",
        "\n",
        "        if keywords_total > 0:\n",
        "            result[\"metrics\"][\"keyword_coverage\"] = keywords_found / keywords_total\n",
        "        else:\n",
        "            result[\"metrics\"][\"keyword_coverage\"] = 1.0\n",
        "\n",
        "        # Check it's not a refusal\n",
        "        refusal_phrases = [\"don't have information\", \"cannot find\", \"no information\", \"i don't know\"]\n",
        "        is_refusal = any(phrase in answer_lower for phrase in refusal_phrases)\n",
        "        result[\"metrics\"][\"correctly_answered\"] = not is_refusal\n",
        "\n",
        "    else:\n",
        "        # Should refuse to answer\n",
        "        refusal_phrases = [\"don't have information\", \"cannot find\", \"no information\", \"i don't know\"]\n",
        "        is_refusal = any(phrase in answer_lower for phrase in refusal_phrases)\n",
        "        result[\"metrics\"][\"correctly_refused\"] = is_refusal\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ZBxKyyAvW0gR"
      },
      "outputs": [],
      "source": [
        "def run_evaluation(test_cases, rag_function):\n",
        "    \"\"\"Run all test cases through the RAG system.\"\"\"\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for i, tc in enumerate(test_cases):\n",
        "        print(f\"Testing {i+1}/{len(test_cases)}: {tc['question'][:50]}...\")\n",
        "\n",
        "        # Get answer\n",
        "        answer = rag_function(tc[\"question\"])\n",
        "\n",
        "        # Evaluate\n",
        "        result = evaluate_answer(answer, tc)\n",
        "        results.append(result)\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4wL4ZWE1W0gR"
      },
      "source": [
        "## Compare Simple vs Production RAG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ta3SiYLoW0gR"
      },
      "outputs": [],
      "source": [
        "# Simple RAG function\n",
        "def simple_rag(query):\n",
        "    docs = vector_store.similarity_search(query, k=3)\n",
        "    return generate_answer(query, docs)\n",
        "\n",
        "# Production RAG function\n",
        "def production_rag(query):\n",
        "    # Hybrid search\n",
        "    docs, _ = hybrid_search(query, k=6)\n",
        "\n",
        "    # Rerank\n",
        "    reranked = rerank_documents(query, docs, top_n=3)\n",
        "    top_docs = [doc for doc, _ in reranked]\n",
        "\n",
        "    # Relevance check\n",
        "    if not check_relevance(query, top_docs):\n",
        "        return \"I don't have information about this topic in the documentation.\"\n",
        "\n",
        "    # Generate\n",
        "    answer = generate_answer(query, top_docs)\n",
        "\n",
        "    return answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "tjOqc1KzW0gR",
        "outputId": "a1b79490-15c7-4807-c85d-a9b370a93e49",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================================\n",
            "EVALUATING SIMPLE RAG\n",
            "==================================================\n",
            "Testing 1/5: How do I authenticate API requests?...\n",
            "Testing 2/5: What is the endpoint for creating a payment?...\n",
            "Testing 3/5: What error codes can the API return?...\n",
            "Testing 4/5: How do I integrate with Stripe?...\n",
            "Testing 5/5: What is the meaning of life?...\n"
          ]
        }
      ],
      "source": [
        "print(\"=\" * 50)\n",
        "print(\"EVALUATING SIMPLE RAG\")\n",
        "print(\"=\" * 50)\n",
        "simple_results = run_evaluation(test_cases, simple_rag)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "MjSBGof_W0gS",
        "outputId": "f6feecc4-3ea7-4c6e-d93b-80fedcf31c64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "EVALUATING PRODUCTION RAG\n",
            "==================================================\n",
            "Testing 1/5: How do I authenticate API requests?...\n",
            "Testing 2/5: What is the endpoint for creating a payment?...\n",
            "Testing 3/5: What error codes can the API return?...\n",
            "Testing 4/5: How do I integrate with Stripe?...\n",
            "Testing 5/5: What is the meaning of life?...\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"EVALUATING PRODUCTION RAG\")\n",
        "print(\"=\" * 50)\n",
        "production_results = run_evaluation(test_cases, production_rag)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "aqPxHuOcW0gT",
        "outputId": "1917a218-4205-4a4f-a90d-81450422c5ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "COMPARISON\n",
            "==================================================\n",
            "\n",
            "Q: How do I authenticate API requests?\n",
            "Should answer: True\n",
            "\n",
            "Simple RAG:\n",
            "  {'keyword_coverage': 1.0, 'correctly_answered': True}\n",
            "Production RAG:\n",
            "  {'keyword_coverage': 1.0, 'correctly_answered': True}\n",
            "\n",
            "Q: What is the endpoint for creating a payment?\n",
            "Should answer: True\n",
            "\n",
            "Simple RAG:\n",
            "  {'keyword_coverage': 0.3333333333333333, 'correctly_answered': True}\n",
            "Production RAG:\n",
            "  {'keyword_coverage': 0.0, 'correctly_answered': False}\n",
            "\n",
            "Q: What error codes can the API return?\n",
            "Should answer: True\n",
            "\n",
            "Simple RAG:\n",
            "  {'keyword_coverage': 0.6, 'correctly_answered': True}\n",
            "Production RAG:\n",
            "  {'keyword_coverage': 0.4, 'correctly_answered': True}\n",
            "\n",
            "Q: How do I integrate with Stripe?\n",
            "Should answer: False\n",
            "\n",
            "Simple RAG:\n",
            "  {'correctly_refused': False}\n",
            "Production RAG:\n",
            "  {'correctly_refused': True}\n",
            "\n",
            "Q: What is the meaning of life?\n",
            "Should answer: False\n",
            "\n",
            "Simple RAG:\n",
            "  {'correctly_refused': False}\n",
            "Production RAG:\n",
            "  {'correctly_refused': True}\n"
          ]
        }
      ],
      "source": [
        "# Compare results\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"COMPARISON\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "for i, tc in enumerate(test_cases):\n",
        "    print(f\"\\nQ: {tc['question']}\")\n",
        "    print(f\"Should answer: {tc['should_answer']}\")\n",
        "    print(f\"\\nSimple RAG:\")\n",
        "    print(f\"  {simple_results[i]['metrics']}\")\n",
        "    print(f\"Production RAG:\")\n",
        "    print(f\"  {production_results[i]['metrics']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x40wWbbZW0gT"
      },
      "source": [
        "## Debugging: When Things Go Wrong\n",
        "\n",
        "When RAG fails, you need to find where in the pipeline it broke:\n",
        "\n",
        "1. **Retrieval problem** â€” Wrong documents retrieved\n",
        "2. **Reranking problem** â€” Good docs scored low\n",
        "3. **Relevance problem** â€” False positive/negative\n",
        "4. **Generation problem** â€” Right docs, wrong answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "hs3L-5aiW0gT"
      },
      "outputs": [],
      "source": [
        "def debug_query(query):\n",
        "    \"\"\"Step through the pipeline and show what happens at each stage.\"\"\"\n",
        "\n",
        "    print(f\"Query: {query}\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Stage 1: Hybrid Search\n",
        "    print(\"\\n[STAGE 1: HYBRID SEARCH]\")\n",
        "    docs, scores = hybrid_search(query, k=6)\n",
        "    print(f\"Retrieved {len(docs)} documents\")\n",
        "    for i, (doc, score) in enumerate(zip(docs[:3], scores[:3])):\n",
        "        print(f\"  {i+1}. (score: {score:.4f}) {doc.page_content[:60]}...\")\n",
        "\n",
        "    # Stage 2: Reranking\n",
        "    print(\"\\n[STAGE 2: RERANKING]\")\n",
        "    reranked = rerank_documents(query, docs, top_n=3)\n",
        "    rerank_scores = [score for _, score in reranked]\n",
        "    print(f\"Rerank scores: {rerank_scores}\")\n",
        "    top_docs = [doc for doc, _ in reranked]\n",
        "    for i, (doc, score) in enumerate(reranked):\n",
        "        print(f\"  {i+1}. (score: {score}/10) {doc.page_content[:60]}...\")\n",
        "\n",
        "    # Stage 3: Relevance Check\n",
        "    print(\"\\n[STAGE 3: RELEVANCE CHECK]\")\n",
        "    is_relevant = check_relevance(query, top_docs)\n",
        "    print(f\"Is relevant: {is_relevant}\")\n",
        "\n",
        "    if not is_relevant:\n",
        "        print(\"\\nPipeline stopped: Documents not relevant\")\n",
        "        return\n",
        "\n",
        "    # Stage 4: Generate\n",
        "    print(\"\\n[STAGE 4: GENERATE ANSWER]\")\n",
        "    answer = generate_answer(query, top_docs)\n",
        "    print(f\"Answer: {answer[:300]}...\")\n",
        "\n",
        "    # Stage 5: Grounding\n",
        "    print(\"\\n[STAGE 5: GROUNDING CHECK]\")\n",
        "    is_grounded = check_grounding(answer, top_docs)\n",
        "    print(f\"Is grounded: {is_grounded}\")\n",
        "\n",
        "    if is_grounded:\n",
        "        print(\"\\nPipeline complete: Answer is grounded\")\n",
        "    else:\n",
        "        print(\"\\nWarning: Answer may contain hallucinations\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "knSFouh2W0gT",
        "outputId": "6137dbed-164e-489e-8885-b3033a9bc41b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: How do I authenticate API requests?\n",
            "============================================================\n",
            "\n",
            "[STAGE 1: HYBRID SEARCH]\n",
            "Retrieved 6 documents\n",
            "  1. (score: 0.0328) # ĞĞ²Ñ‚Ğ¾Ñ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ\n",
            "\n",
            "> Ğ”Ğ»Ñ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²ĞºĞ¸ Ğ°Ğ²Ñ‚Ğ¾Ñ€Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ² Ğ½ĞµĞ¾Ğ±...\n",
            "  2. (score: 0.0161) # Ğ ĞµĞºĞ²Ğ¸Ğ·Ğ¸Ñ‚Ñ‹ Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ°Ñ‚ĞµĞ»Ñ\n",
            "\n",
            "## OpenAPI Specification...\n",
            "  3. (score: 0.0161) # Introduction\n",
            "\n",
            "ĞŸĞ»Ğ°Ñ‚ĞµĞ¶Ğ½Ñ‹Ğ¹ ÑˆĞ»ÑĞ· Multicard\n",
            "\n",
            "Ğ”Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ñ API Ğ´...\n",
            "\n",
            "[STAGE 2: RERANKING]\n",
            "Rerank scores: [10.0, 2.0, 2.0]\n",
            "  1. (score: 10.0/10) # ĞĞ²Ñ‚Ğ¾Ñ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ\n",
            "\n",
            "> Ğ”Ğ»Ñ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²ĞºĞ¸ Ğ°Ğ²Ñ‚Ğ¾Ñ€Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ² Ğ½ĞµĞ¾Ğ±...\n",
            "  2. (score: 2.0/10) # Ğ ĞµĞºĞ²Ğ¸Ğ·Ğ¸Ñ‚Ñ‹ Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ°Ñ‚ĞµĞ»Ñ\n",
            "\n",
            "## OpenAPI Specification...\n",
            "  3. (score: 2.0/10) # Introduction\n",
            "\n",
            "ĞŸĞ»Ğ°Ñ‚ĞµĞ¶Ğ½Ñ‹Ğ¹ ÑˆĞ»ÑĞ· Multicard\n",
            "\n",
            "Ğ”Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ñ API Ğ´...\n",
            "\n",
            "[STAGE 3: RELEVANCE CHECK]\n",
            "Is relevant: True\n",
            "\n",
            "[STAGE 4: GENERATE ANSWER]\n",
            "Answer: To authenticate API requests, you need to obtain a token and send it in the header of subsequent requests as follows:\n",
            "\n",
            "`Authorization: Bearer {token}`\n",
            "\n",
            "The token has an expiry date specified in the field expiry (24 hours from the time of issuance). After this period, requests to the API will return ...\n",
            "\n",
            "[STAGE 5: GROUNDING CHECK]\n",
            "Is grounded: True\n",
            "\n",
            "âœ… Pipeline complete: Answer is grounded\n"
          ]
        }
      ],
      "source": [
        "# Debug a successful query\n",
        "debug_query(\"How do I authenticate API requests?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "wvmxhOo1W0gU",
        "outputId": "15fb1a01-aa89-4d60-9207-49802fadee0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: How do I integrate with PayPal?\n",
            "============================================================\n",
            "\n",
            "[STAGE 1: HYBRID SEARCH]\n",
            "Retrieved 6 documents\n",
            "  1. (score: 0.0164) ĞŸÑ€Ğ¸ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğ¸ Ğ¿Ğ»Ğ°Ñ‚ĞµĞ¶Ğ° Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Ğ´Ğ°Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ°, Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²ĞºĞ° Ğ·Ğ°Ğ¿...\n",
            "  2. (score: 0.0164) x-apidog-orders:\n",
            "                      - code\n",
            "              ...\n",
            "  3. (score: 0.0161) ĞŸÑ€Ğ¾ÑÑ‚Ğ°Ñ Ğ¾Ğ¿Ğ»Ğ°Ñ‚Ğ° Ğ¿ÑƒÑ‚ĞµĞ¼ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ñ Ğ¸Ğ½Ğ²Ğ¾Ğ¹ÑĞ° Ğ¸ Ğ¿ĞµÑ€ĞµĞ½Ğ°Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ğ¿Ğ¾ Ñ...\n",
            "\n",
            "[STAGE 2: RERANKING]\n",
            "Rerank scores: [8.0, 5.0, 3.0]\n",
            "  1. (score: 8.0/10) ```...\n",
            "  2. (score: 5.0/10) ĞŸÑ€Ğ¾ÑÑ‚Ğ°Ñ Ğ¾Ğ¿Ğ»Ğ°Ñ‚Ğ° Ğ¿ÑƒÑ‚ĞµĞ¼ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ñ Ğ¸Ğ½Ğ²Ğ¾Ğ¹ÑĞ° Ğ¸ Ğ¿ĞµÑ€ĞµĞ½Ğ°Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ğ¿Ğ¾ Ñ...\n",
            "  3. (score: 3.0/10) ĞŸÑ€Ğ¸ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğ¸ Ğ¿Ğ»Ğ°Ñ‚ĞµĞ¶Ğ° Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Ğ´Ğ°Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ°, Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²ĞºĞ° Ğ·Ğ°Ğ¿...\n",
            "\n",
            "[STAGE 3: RELEVANCE CHECK]\n",
            "Is relevant: False\n",
            "\n",
            "âŒ Pipeline stopped: Documents not relevant\n"
          ]
        }
      ],
      "source": [
        "# Debug a query that should fail\n",
        "debug_query(\"How do I integrate with PayPal?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPrXW30bW0gU"
      },
      "source": [
        "## Common Failure Patterns\n",
        "\n",
        "### 1. Retrieval Failure\n",
        "The right documents aren't being found.\n",
        "\n",
        "**Symptoms:** Rerank scores are all low (< 5)\n",
        "\n",
        "**Fixes:**\n",
        "- Improve chunking (keep related content together)\n",
        "- Add metadata to help filtering\n",
        "- Tune BM25/vector weights in hybrid search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "7DNPfvjrW0gU",
        "outputId": "359809ee-8c9e-4961-ef62-b8940b18d9ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: How do I create a payment?\n",
            "Scores: [9.0, 7.0, 2.0]\n",
            "Average: 6.0, Max: 9.0\n",
            "âœ… Retrieval looks good\n"
          ]
        }
      ],
      "source": [
        "# Example: Check if retrieval is the problem\n",
        "def diagnose_retrieval(query):\n",
        "    docs, _ = hybrid_search(query, k=6)\n",
        "    reranked = rerank_documents(query, docs)\n",
        "    scores = [s for _, s in reranked]\n",
        "\n",
        "    avg_score = sum(scores) / len(scores)\n",
        "    max_score = max(scores)\n",
        "\n",
        "    print(f\"Query: {query}\")\n",
        "    print(f\"Scores: {scores}\")\n",
        "    print(f\"Average: {avg_score:.1f}, Max: {max_score}\")\n",
        "\n",
        "    if max_score < 5:\n",
        "        print(\"RETRIEVAL PROBLEM: No highly relevant docs found\")\n",
        "    elif avg_score < 4:\n",
        "        print(\"PARTIAL PROBLEM: Some relevant docs, but noisy\")\n",
        "    else:\n",
        "        print(\"Retrieval looks good\")\n",
        "\n",
        "diagnose_retrieval(\"How do I create a payment?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3DQ42HNW0gY"
      },
      "source": [
        "### 2. False Refusals\n",
        "The system says \"I don't know\" when the answer IS in the docs.\n",
        "\n",
        "**Symptoms:** Relevance check returns False incorrectly\n",
        "\n",
        "**Fixes:**\n",
        "- Adjust relevance threshold\n",
        "- Improve the relevance prompt\n",
        "- Check if chunking is splitting relevant content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "o7fnoHrRW0gY",
        "outputId": "41dc76cc-042b-4f9c-f726-5301931e1622",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: How do I get an access token?\n",
            "\n",
            "Top doc content:\n",
            "# ĞĞ²Ñ‚Ğ¾Ñ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ\n",
            "\n",
            "> Ğ”Ğ»Ñ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²ĞºĞ¸ Ğ°Ğ²Ñ‚Ğ¾Ñ€Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ² Ğ½ĞµĞ¾Ğ±Ñ…Ğ¾Ğ´Ğ¸Ğ¼Ğ¾ Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ñ‚Ğ¾ĞºĞµĞ½ Ğ¸ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ÑÑ‚ÑŒ ĞµĞ³Ğ¾ Ğ² Ğ¿Ğ¾ÑĞ»ĞµĞ´ÑƒÑÑ‰Ğ¸Ñ… Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ°Ñ… Ğ² Ğ·Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²ĞºĞµ:\n",
            "\n",
            "`Authorization: Bearer {token}`\n",
            "\n",
            "Ğ’ Ğ¿Ğ¾Ğ»Ğµ expiry ÑƒĞºĞ°Ğ·Ğ°Ğ½Ğ° Ğ´Ğ°Ñ‚Ğ° ÑƒÑÑ‚Ğ°Ñ€ĞµĞ²Ğ°Ğ½Ğ¸Ñ Ñ‚Ğ¾ĞºĞµĞ½Ğ° (24 Ñ‡Ğ°ÑĞ° Ñ Ğ¼Ğ¾Ğ¼ĞµĞ½Ñ‚Ğ° Ğ²Ñ‹Ğ¿ÑƒÑĞºĞ° Ñ‚Ğ¾ĞºĞµĞ½Ğ°). ĞŸĞ¾ÑĞ»Ğµ ÑÑ‚Ğ¾Ğ³Ğ¾ ÑÑ€Ğ¾ĞºĞ° Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑÑ‹ Ğº API Ğ±ÑƒĞ´ÑƒÑ‚ Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°Ñ‚ÑŒ Ğ¾ÑˆĞ¸Ğ±ĞºÑƒ (HTTP STATUS) 401 Unauthorized. ĞĞµ Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´ÑƒĞµÑ‚ÑÑ Ğ·Ğ°Ğ¿Ñ€Ğ°ÑˆĞ¸Ğ²Ğ°Ñ‚ÑŒ Ñ‚Ğ¾ĞºĞµĞ½ Ğ¿ĞµÑ€ĞµĞ´ ĞºĞ°Ğ¶Ğ´Ñ‹Ğ¼ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ¼ â€“ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° Ğ¿Ğ¾ÑÑ‚Ğ°Ğ²Ñ‰Ğ¸ĞºĞ° Ğ´Ğ¾Ğ»Ğ¶Ğ½Ğ° Ğ±Ñ‹Ñ‚ÑŒ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞ½Ğ° Ğ½Ğ° ĞºĞµÑˆĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ñ‚Ğ¾ĞºĞµĞ½Ğ° Ğ½Ğ° ÑÑ€Ğ¾Ğº ĞµĞ³Ğ¾ Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ñ.\n",
            "\n",
            "Ğ”Ğ»Ñ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²ĞºĞ¸ Ğ°Ğ²Ñ‚\n",
            "\n",
            "Relevance check result: True\n"
          ]
        }
      ],
      "source": [
        "# Check what the relevance check sees\n",
        "def diagnose_relevance(query):\n",
        "    docs, _ = hybrid_search(query, k=6)\n",
        "    reranked = rerank_documents(query, docs, top_n=3)\n",
        "    top_docs = [doc for doc, _ in reranked]\n",
        "\n",
        "    print(f\"Query: {query}\")\n",
        "    print(f\"\\nTop doc content:\")\n",
        "    print(top_docs[0].page_content[:500])\n",
        "    print(f\"\\nRelevance check result: {check_relevance(query, top_docs)}\")\n",
        "\n",
        "diagnose_relevance(\"How do I get an access token?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTKllgNNW0gY"
      },
      "source": [
        "### 3. Hallucination\n",
        "The answer includes information not in the documents.\n",
        "\n",
        "**Symptoms:** Grounding check fails, or answer contains specific details not in context\n",
        "\n",
        "**Fixes:**\n",
        "- Strengthen the generation prompt\n",
        "- Lower temperature\n",
        "- Add explicit \"only use provided context\" instructions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Re4Qf05-W0gZ",
        "outputId": "1f3f5876-8602-43c2-81ff-163dc3663ccc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: How do I authenticate?\n",
            "\n",
            "Answer: To authenticate, you need to obtain a token and include it in the header of your requests as follows:\n",
            "\n",
            "`Authorization: Bearer {token}`\n",
            "\n",
            "Make sure to check the expiry date of the token, which is 24 hours from the time it is issued. After this period, requests to the API will return a 401 Unauthorized\n",
            "\n",
            "Grounded: True\n"
          ]
        }
      ],
      "source": [
        "# Check for hallucination\n",
        "def diagnose_hallucination(query):\n",
        "    docs, _ = hybrid_search(query, k=6)\n",
        "    reranked = rerank_documents(query, docs, top_n=3)\n",
        "    top_docs = [doc for doc, _ in reranked]\n",
        "\n",
        "    answer = generate_answer(query, top_docs)\n",
        "    is_grounded = check_grounding(answer, top_docs)\n",
        "\n",
        "    print(f\"Query: {query}\")\n",
        "    print(f\"\\nAnswer: {answer[:300]}\")\n",
        "    print(f\"\\nGrounded: {is_grounded}\")\n",
        "\n",
        "    if not is_grounded:\n",
        "        print(\"\\nHALLUCINATION DETECTED\")\n",
        "        print(\"Check: Does the answer contain info not in the docs?\")\n",
        "\n",
        "diagnose_hallucination(\"How do I authenticate?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhWmvq9FW0gZ"
      },
      "source": [
        "## Building a Feedback Loop\n",
        "\n",
        "The best RAG systems improve over time by collecting user feedback."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "VbmTCTizW0gZ"
      },
      "outputs": [],
      "source": [
        "# Simple feedback collection\n",
        "feedback_log = []\n",
        "\n",
        "def rag_with_feedback(query):\n",
        "    \"\"\"RAG that collects feedback.\"\"\"\n",
        "\n",
        "    # Get answer\n",
        "    answer = production_rag(query)\n",
        "\n",
        "    # Log for review\n",
        "    entry = {\n",
        "        \"query\": query,\n",
        "        \"answer\": answer,\n",
        "        \"feedback\": None  # To be filled by user\n",
        "    }\n",
        "    feedback_log.append(entry)\n",
        "\n",
        "    return answer, len(feedback_log) - 1  # Return answer and log ID\n",
        "\n",
        "def submit_feedback(log_id, is_helpful, comment=\"\"):\n",
        "    \"\"\"Submit feedback for an answer.\"\"\"\n",
        "    feedback_log[log_id][\"feedback\"] = {\n",
        "        \"helpful\": is_helpful,\n",
        "        \"comment\": comment\n",
        "    }\n",
        "    print(f\"Feedback recorded: {'ğŸ‘' if is_helpful else 'ğŸ‘'}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "KQbRIA1OW0gZ",
        "outputId": "e37bd108-bb83-42a9-85e6-9103e02a6d77",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: To create a payment, follow these steps:\n",
            "\n",
            "1. The Partner's system creates an invoice and receives a link to the payment page.\n",
            "2. The user makes the payment by adding their card or using payment applic...\n",
            "Log ID: 0\n"
          ]
        }
      ],
      "source": [
        "# Example usage\n",
        "answer, log_id = rag_with_feedback(\"How do I create a payment?\")\n",
        "print(f\"Answer: {answer[:200]}...\")\n",
        "print(f\"Log ID: {log_id}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "cMmL0i0aW0gZ",
        "outputId": "2a896d13-6b04-45e0-a005-6fadbefda239",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feedback recorded: ğŸ‘\n"
          ]
        }
      ],
      "source": [
        "# Submit feedback\n",
        "submit_feedback(log_id, is_helpful=True, comment=\"Clear and complete\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "E7frwe53W0gZ",
        "outputId": "de8c75bc-ca8e-4ad8-d80b-c0031754e92f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "  {\n",
            "    \"query\": \"How do I create a payment?\",\n",
            "    \"answer\": \"To create a payment, follow these steps:\\n\\n1. The Partner's system creates an invoice and receives a link to the payment page.\\n2. The user makes the payment by adding their card or using payment applications (such as Payme, Click, Uzumbank, Anorbank, Oson, Alif, Xazna, Beepul, Trastpay).\\n3. Upon successful payment, the Multicard payment gateway sends a callback request to the Partner's system. Additionally, webhooks can be configured to send notifications for each change in the transaction status.\",\n",
            "    \"feedback\": {\n",
            "      \"helpful\": true,\n",
            "      \"comment\": \"Clear and complete\"\n",
            "    }\n",
            "  }\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "# View feedback log\n",
        "import json\n",
        "print(json.dumps(feedback_log, indent=2, default=str))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7U6ahm-cW0ga"
      },
      "source": [
        "## Summary\n",
        "\n",
        "**What we learned:**\n",
        "\n",
        "1. **Test cases are essential** â€” Define questions + expected answers\n",
        "2. **Measure at each stage** â€” Find where failures happen\n",
        "3. **Common problems:**\n",
        "   - Retrieval failure â†’ Improve search/chunking\n",
        "   - False refusals â†’ Tune relevance check\n",
        "   - Hallucinations â†’ Strengthen generation prompt\n",
        "4. **Collect feedback** â€” Improve over time\n",
        "\n",
        "**Key insight:** A debuggable system beats a clever system. Always know what's happening inside."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "1gikjY-7W0ga",
        "outputId": "281e0a3f-944e-427f-e405-7c8330c04730",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Workshop complete!\n",
            "\n",
            "You've learned:\n",
            "  1. Why simple RAG fails (30% accuracy)\n",
            "  2. How to build production RAG (86% accuracy)\n",
            "  3. How to evaluate and debug\n",
            "\n",
            "Next steps:\n",
            "  - Try with your own documents\n",
            "  - Build a web interface\n",
            "  - Add streaming responses\n",
            "  - Deploy to production\n"
          ]
        }
      ],
      "source": [
        "print(\"Workshop complete!\")\n",
        "print(\"\")\n",
        "print(\"You've learned:\")\n",
        "print(\"  1. Why simple RAG fails (30% accuracy)\")\n",
        "print(\"  2. How to build production RAG (86% accuracy)\")\n",
        "print(\"  3. How to evaluate and debug\")\n",
        "print(\"\")\n",
        "print(\"Next steps:\")\n",
        "print(\"  - Try with your own documents\")\n",
        "print(\"  - Build a web interface\")\n",
        "print(\"  - Add streaming responses\")\n",
        "print(\"  - Deploy to production\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}