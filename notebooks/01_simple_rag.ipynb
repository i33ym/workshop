{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Simple RAG\n",
    "\n",
    "In this notebook, we'll build a basic RAG system and see why it doesn't work well.\n",
    "\n",
    "**What is RAG?**\n",
    "- **R**etrieval — find relevant documents\n",
    "- **A**ugmented — add them to the AI's context\n",
    "- **G**eneration — generate an answer\n",
    "\n",
    "By the end, you'll understand why simple RAG only achieves ~30% accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Setup\n",
    "\n",
    "Run this cell first to clone the repo and install dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/i33ym/rag-workshop.git 2>/dev/null || echo \"Already cloned\"\n",
    "%cd rag-workshop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q openai langchain langchain-openai langchain-community chromadb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Set Your API Key\n",
    "\n",
    "Get your OpenAI API key from [platform.openai.com](https://platform.openai.com/api-keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter your OpenAI API key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load the Documents\n",
    "\n",
    "We'll load markdown files from the `docs/` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader, TextLoader\n",
    "\n",
    "loader = DirectoryLoader(\n",
    "    \"docs/\",\n",
    "    glob=\"**/*.md\",\n",
    "    loader_cls=TextLoader\n",
    ")\n",
    "\n",
    "documents = loader.load()\n",
    "print(f\"Loaded {len(documents)} documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Split Into Chunks\n",
    "\n",
    "Documents are too long to process at once. We split them into smaller chunks.\n",
    "\n",
    "**Why chunking matters:**\n",
    "- LLMs have context limits\n",
    "- Smaller chunks = more precise retrieval\n",
    "- But too small = losing context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200\n",
    ")\n",
    "\n",
    "chunks = splitter.split_documents(documents)\n",
    "print(f\"Split into {len(chunks)} chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at one chunk\n",
    "print(\"=== Sample Chunk ===\")\n",
    "print(chunks[0].page_content[:500])\n",
    "print(\"\\n=== Metadata ===\")\n",
    "print(chunks[0].metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Create Embeddings\n",
    "\n",
    "**What are embeddings?**\n",
    "\n",
    "Embeddings convert text into numbers (vectors) that capture meaning.\n",
    "\n",
    "Similar texts have similar vectors. This lets us find relevant documents by comparing vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# Test it\n",
    "test_embedding = embeddings.embed_query(\"How do I authenticate?\")\n",
    "print(f\"Embedding dimension: {len(test_embedding)}\")\n",
    "print(f\"First 5 values: {test_embedding[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Create Vector Store\n",
    "\n",
    "A vector store holds all our chunk embeddings and lets us search by similarity.\n",
    "\n",
    "We'll use ChromaDB (runs in memory, no setup needed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "vector_store = Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embeddings\n",
    ")\n",
    "\n",
    "print(f\"Vector store created with {len(chunks)} chunks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Test Retrieval\n",
    "\n",
    "Let's search for relevant documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How do I get an authorization token?\"\n",
    "\n",
    "results = vector_store.similarity_search(query, k=3)\n",
    "\n",
    "print(f\"Query: {query}\\n\")\n",
    "for i, doc in enumerate(results):\n",
    "    print(f\"=== Result {i+1} ===\")\n",
    "    print(doc.page_content[:300])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Build Simple RAG\n",
    "\n",
    "Now let's combine retrieval with generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "Answer the question based only on the following context.\n",
    "If you can't find the answer, say \"I don't know.\"\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\n",
    "\"\"\")\n",
    "\n",
    "def simple_rag(question):\n",
    "    # Retrieve\n",
    "    docs = vector_store.similarity_search(question, k=3)\n",
    "    context = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "    \n",
    "    # Generate\n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "    answer = chain.invoke({\"context\": context, \"question\": question})\n",
    "    \n",
    "    return answer, docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test it!\n",
    "question = \"How do I get an authorization token?\"\n",
    "\n",
    "answer, docs = simple_rag(question)\n",
    "\n",
    "print(f\"Question: {question}\\n\")\n",
    "print(f\"Answer: {answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Test More Questions\n",
    "\n",
    "Let's see how well it performs on different types of questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_questions = [\n",
    "    \"How do I create a payment?\",\n",
    "    \"What error codes can the API return?\",\n",
    "    \"How do I set up webhooks?\",\n",
    "    \"What is the endpoint for checking payment status?\",\n",
    "    \"How do I authenticate API requests?\"\n",
    "]\n",
    "\n",
    "for q in test_questions:\n",
    "    answer, _ = simple_rag(q)\n",
    "    print(f\"Q: {q}\")\n",
    "    print(f\"A: {answer[:200]}...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problems with Simple RAG\n",
    "\n",
    "You probably noticed some issues:\n",
    "\n",
    "### 1. Retrieval misses exact terms\n",
    "Vector search is semantic — it finds similar *meanings*, not exact *words*.\n",
    "\n",
    "If you search for `POST /api/v1/payment`, you might get docs about \"creating payments\" instead of the actual endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try an exact endpoint search\n",
    "results = vector_store.similarity_search(\"POST /api/payment/create\", k=3)\n",
    "\n",
    "print(\"Searching for exact endpoint 'POST /api/payment/create':\\n\")\n",
    "for i, doc in enumerate(results):\n",
    "    print(f\"Result {i+1}: {doc.page_content[:150]}...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. No relevance verification\n",
    "Even if documents aren't really relevant, we still generate an answer from them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask about something NOT in the docs\n",
    "answer, docs = simple_rag(\"How do I integrate with Stripe?\")\n",
    "\n",
    "print(f\"Question about something NOT in docs:\\n\")\n",
    "print(f\"Answer: {answer}\")\n",
    "print(f\"\\n(Notice: it might hallucinate or give wrong info)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. All retrieved docs are used equally\n",
    "Some retrieved documents are more relevant than others, but we treat them all the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at similarity scores\n",
    "results_with_scores = vector_store.similarity_search_with_score(\"How do I authenticate?\", k=5)\n",
    "\n",
    "print(\"Similarity scores (lower = more similar):\\n\")\n",
    "for doc, score in results_with_scores:\n",
    "    print(f\"Score: {score:.3f} | {doc.page_content[:60]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark Results\n",
    "\n",
    "Research comparing 18 RAG techniques found:\n",
    "\n",
    "| Technique | Accuracy |\n",
    "|-----------|----------|\n",
    "| **Simple RAG** | **0.30** |\n",
    "| Semantic Chunking | 0.20 |\n",
    "| HyDE | 0.50 |\n",
    "| Reranker | 0.70 |\n",
    "| Hybrid Search | 0.83 |\n",
    "| Adaptive RAG | 0.86 |\n",
    "\n",
    "Simple RAG only gets 30% right. We can do much better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**What we built:**\n",
    "- Loaded documents\n",
    "- Split into chunks\n",
    "- Created embeddings\n",
    "- Built a vector store\n",
    "- Combined retrieval + generation\n",
    "\n",
    "**Why it's not enough:**\n",
    "- Vector search misses exact matches\n",
    "- No relevance verification\n",
    "- No reranking of results\n",
    "- No hallucination prevention\n",
    "\n",
    "**Next notebook:** We'll fix all of these problems and build a production-ready system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"✅ Part 1 complete!\")\n",
    "print(\"Next: Open 02_production_rag.ipynb\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
