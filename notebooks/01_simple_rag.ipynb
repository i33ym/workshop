{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UShF8D3xLWI0"
      },
      "source": [
        "# Part 1: Simple RAG\n",
        "\n",
        "In this notebook, we'll build a basic RAG system and see why it doesn't work well.\n",
        "\n",
        "**What is RAG?**\n",
        "- **R**etrieval — find relevant documents\n",
        "- **A**ugmented — add them to the AI's context\n",
        "- **G**eneration — generate an answer\n",
        "\n",
        "By the end, you'll understand why simple RAG only achieves ~30% accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RoFY1D0LWI2"
      },
      "source": [
        "## Step 0: Setup\n",
        "\n",
        "Run this cell first to clone the repo and install dependencies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFRCI3SILWI3",
        "outputId": "b052f952-d190-47b4-d113-db0ad5792d7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/workshop\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/i33ym/workshop.git 2>/dev/null || echo \"Already cloned\"\n",
        "%cd workshop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "b-oqoG4jLWI4"
      },
      "outputs": [],
      "source": [
        "!pip install -q openai langchain langchain-openai langchain-community langchain-text-splitters chromadb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XW3lPQzLWI5"
      },
      "source": [
        "## Step 1: Set Your API Key\n",
        "\n",
        "Get your OpenAI API key from [platform.openai.com](https://platform.openai.com/api-keys)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioJbNQYELWI6",
        "outputId": "ebcf1341-5d16-4c72-8172-685e383064d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your OpenAI API key: ··········\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter your OpenAI API key: \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8_qmQ6lLWI7"
      },
      "source": [
        "## Step 2: Load the Documents\n",
        "\n",
        "We'll load markdown files from the `docs/` folder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgb5HBvdLWI8",
        "outputId": "5a6cbdcb-9335-4451-ad70-ef7c716942f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 58 documents\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.document_loaders import DirectoryLoader, TextLoader\n",
        "\n",
        "loader = DirectoryLoader(\n",
        "    \"docs/\",\n",
        "    glob=\"**/*.md\",\n",
        "    loader_cls=TextLoader\n",
        ")\n",
        "\n",
        "documents = loader.load()\n",
        "print(f\"Loaded {len(documents)} documents\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UCc1kZ6LWI9"
      },
      "source": [
        "## Step 3: Split Into Chunks\n",
        "\n",
        "Documents are too long to process at once. We split them into smaller chunks.\n",
        "\n",
        "**Why chunking matters:**\n",
        "- LLMs have context limits\n",
        "- Smaller chunks = more precise retrieval\n",
        "- But too small = losing context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ug773UeMLWI-",
        "outputId": "044d295a-833a-453d-e7a5-927ea3d851b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Split into 679 chunks\n"
          ]
        }
      ],
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=200\n",
        ")\n",
        "\n",
        "chunks = splitter.split_documents(documents)\n",
        "print(f\"Split into {len(chunks)} chunks\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-TOgwuILWI-",
        "outputId": "26912407-a0d2-43db-823c-0ada29bc9274"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Sample Chunk ===\n",
            "# storeModel\n",
            "\n",
            "## OpenAPI Specification\n",
            "\n",
            "=== Metadata ===\n",
            "{'source': 'docs/52.md'}\n"
          ]
        }
      ],
      "source": [
        "# Let's look at one chunk\n",
        "print(\"=== Sample Chunk ===\")\n",
        "print(chunks[0].page_content[:500])\n",
        "print(\"\\n=== Metadata ===\")\n",
        "print(chunks[0].metadata)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bx9pW3lLLWI-"
      },
      "source": [
        "## Step 4: Create Embeddings\n",
        "\n",
        "**What are embeddings?**\n",
        "\n",
        "Embeddings convert text into numbers (vectors) that capture meaning.\n",
        "\n",
        "Similar texts have similar vectors. This lets us find relevant documents by comparing vectors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYIbWe48LWI_",
        "outputId": "07373ffd-8559-4787-a2f5-25d189379eef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding dimension: 1536\n",
            "First 5 values: [-0.023669837042689323, 0.011893004179000854, -0.011457362212240696, 0.013490354642271996, 0.015828296542167664]\n"
          ]
        }
      ],
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
        "\n",
        "# Test it\n",
        "test_embedding = embeddings.embed_query(\"How do I authenticate?\")\n",
        "print(f\"Embedding dimension: {len(test_embedding)}\")\n",
        "print(f\"First 5 values: {test_embedding[:5]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzGZqsbJLWI_"
      },
      "source": [
        "## Step 5: Create Vector Store\n",
        "\n",
        "A vector store holds all our chunk embeddings and lets us search by similarity.\n",
        "\n",
        "We'll use ChromaDB (runs in memory, no setup needed)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iToBAYt1LWI_",
        "outputId": "44bf378c-0e6d-4574-fa26-eca328b203ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector store created with 679 chunks\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.vectorstores import Chroma\n",
        "\n",
        "vector_store = Chroma.from_documents(\n",
        "    documents=chunks,\n",
        "    embedding=embeddings\n",
        ")\n",
        "\n",
        "print(f\"Vector store created with {len(chunks)} chunks\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MbCJyD2LWI_"
      },
      "source": [
        "## Step 6: Test Retrieval\n",
        "\n",
        "Let's search for relevant documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PhHvAHOTLWI_",
        "outputId": "451fe752-6f4a-4a75-cd9b-86c0e3845f37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: How do I get an authorization token?\n",
            "\n",
            "=== Result 1 ===\n",
            "# Авторизация\n",
            "\n",
            "> Для отправки авторизированных запросов необходимо получить токен и отправлять его в последующих запросах в заголовке:\n",
            "\n",
            "`Authorization: Bearer {token}`\n",
            "\n",
            "В поле expiry указана дата устаревания токена (24 часа с момента выпуска токена). После этого срока запросы к API будут возвращать \n",
            "\n",
            "=== Result 2 ===\n",
            "example:\n",
            "              application_id: rhmt_test\n",
            "              secret: Pw18axeBFo8V7NamKHXX\n",
            "      responses:\n",
            "        '200':\n",
            "          description: ''\n",
            "          content:\n",
            "            application/json:\n",
            "              schema:\n",
            "                type: object\n",
            "                properties:\n",
            "                  toke\n",
            "\n",
            "=== Result 3 ===\n",
            "запросить заново. Временная зона GMT+5\n",
            "                required:\n",
            "                  - token\n",
            "                  - role\n",
            "                  - expiry\n",
            "                x-apidog-orders:\n",
            "                  - token\n",
            "                  - role\n",
            "                  - expiry\n",
            "              example:\n",
            "                token: \n",
            "\n"
          ]
        }
      ],
      "source": [
        "query = \"How do I get an authorization token?\"\n",
        "\n",
        "results = vector_store.similarity_search(query, k=3)\n",
        "\n",
        "print(f\"Query: {query}\\n\")\n",
        "for i, doc in enumerate(results):\n",
        "    print(f\"=== Result {i+1} ===\")\n",
        "    print(doc.page_content[:300])\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMMRAMqcLWJA"
      },
      "source": [
        "## Step 7: Build Simple RAG\n",
        "\n",
        "Now let's combine retrieval with generation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "CwxpR03LLWJA"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
        "Answer the question based only on the following context.\n",
        "If you can't find the answer, say \"I don't know.\"\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Answer:\n",
        "\"\"\")\n",
        "\n",
        "def simple_rag(question):\n",
        "    # Retrieve\n",
        "    docs = vector_store.similarity_search(question, k=3)\n",
        "    context = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
        "\n",
        "    # Generate\n",
        "    chain = prompt | llm | StrOutputParser()\n",
        "    answer = chain.invoke({\"context\": context, \"question\": question})\n",
        "\n",
        "    return answer, docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNqNpIdFLWJB",
        "outputId": "9b2329ca-c1cd-4ffa-a0b6-8156a46065a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: How do I get an authorization token?\n",
            "\n",
            "Answer: To get an authorization token, you need to send a request with the required fields, including your application ID and secret. Upon a successful request, you will receive a JWT token, which you must include in the header of subsequent requests as follows:\n",
            "\n",
            "`Authorization: Bearer {token}`\n",
            "\n",
            "Make sure to check the expiry field in the response, as the token will expire 24 hours after issuance. After that, you will need to request a new token.\n"
          ]
        }
      ],
      "source": [
        "# Test it!\n",
        "question = \"How do I get an authorization token?\"\n",
        "\n",
        "answer, docs = simple_rag(question)\n",
        "\n",
        "print(f\"Question: {question}\\n\")\n",
        "print(f\"Answer: {answer}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6VTzyT5LWJB"
      },
      "source": [
        "## Step 8: Test More Questions\n",
        "\n",
        "Let's see how well it performs on different types of questions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aVrJTENfLWJC",
        "outputId": "34d286a9-ecfa-433e-aba8-0fddd7952a44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q: How do I create a payment?\n",
            "A: To create a payment, follow these steps:\n",
            "\n",
            "1. The Partner's system creates an invoice and receives a link to the payment page in response.\n",
            "2. The user makes the payment by adding a card or using paymen...\n",
            "\n",
            "Q: What error codes can the API return?\n",
            "A: The API can return the error code 400....\n",
            "\n",
            "Q: How do I set up webhooks?\n",
            "A: I don't know....\n",
            "\n",
            "Q: What is the endpoint for checking payment status?\n",
            "A: I don't know....\n",
            "\n",
            "Q: How do I authenticate API requests?\n",
            "A: To authenticate API requests, you need to obtain a token and send it in the header of subsequent requests as follows:\n",
            "\n",
            "`Authorization: Bearer {token}`\n",
            "\n",
            "The token has an expiry date, which is 24 hours ...\n",
            "\n"
          ]
        }
      ],
      "source": [
        "test_questions = [\n",
        "    \"How do I create a payment?\",\n",
        "    \"What error codes can the API return?\",\n",
        "    \"How do I set up webhooks?\",\n",
        "    \"What is the endpoint for checking payment status?\",\n",
        "    \"How do I authenticate API requests?\"\n",
        "]\n",
        "\n",
        "for q in test_questions:\n",
        "    answer, _ = simple_rag(q)\n",
        "    print(f\"Q: {q}\")\n",
        "    print(f\"A: {answer[:200]}...\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOSDfUL7LWJC"
      },
      "source": [
        "## Problems with Simple RAG\n",
        "\n",
        "You probably noticed some issues:\n",
        "\n",
        "### 1. Retrieval misses exact terms\n",
        "Vector search is semantic — it finds similar *meanings*, not exact *words*.\n",
        "\n",
        "If you search for `POST /api/v1/payment`, you might get docs about \"creating payments\" instead of the actual endpoint."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yra1CzXFLWJC",
        "outputId": "17427cb8-0e41-40d5-b04b-a643c0ef8147"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Searching for exact endpoint 'POST /api/payment/create':\n",
            "\n",
            "Result 1: # Создание платежа на выплату c передачей номера карты\n",
            "\n",
            "## OpenAPI Specification...\n",
            "\n",
            "Result 2: # Создание платежа по токену карты\n",
            "\n",
            "## OpenAPI Specification...\n",
            "\n",
            "Result 3: # Создание платежа с передачей карточных данных\n",
            "\n",
            "## OpenAPI Specification\n",
            "\n",
            "```yaml\n",
            "openapi: 3.0.1\n",
            "info:\n",
            "  title: ''\n",
            "  description: ''\n",
            "  version: 1.0.0...\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Try an exact endpoint search\n",
        "results = vector_store.similarity_search(\"POST /api/payment/create\", k=3)\n",
        "\n",
        "print(\"Searching for exact endpoint 'POST /api/payment/create':\\n\")\n",
        "for i, doc in enumerate(results):\n",
        "    print(f\"Result {i+1}: {doc.page_content[:150]}...\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FhtpGsQoLWJC"
      },
      "source": [
        "### 2. No relevance verification\n",
        "Even if documents aren't really relevant, we still generate an answer from them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wrn8HT1MLWJD",
        "outputId": "b69d5f6c-134c-434e-e65c-c18cb72d9665"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question about something NOT in docs:\n",
            "\n",
            "Answer: I don't know.\n",
            "\n",
            "(Notice: it might hallucinate or give wrong info)\n"
          ]
        }
      ],
      "source": [
        "# Ask about something NOT in the docs\n",
        "answer, docs = simple_rag(\"How do I integrate with Stripe?\")\n",
        "\n",
        "print(f\"Question about something NOT in docs:\\n\")\n",
        "print(f\"Answer: {answer}\")\n",
        "print(f\"\\n(Notice: it might hallucinate or give wrong info)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIbt1mExLWJD"
      },
      "source": [
        "### 3. All retrieved docs are used equally\n",
        "Some retrieved documents are more relevant than others, but we treat them all the same."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kI7Phm2qLWJD",
        "outputId": "fa29142c-aa87-41ad-ec31-9ad4be62bddf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity scores (lower = more similar):\n",
            "\n",
            "Score: 1.217 | - is_commitent\n",
            "        - active\n",
            "      required:\n",
            "        - id...\n",
            "Score: 1.260 | otp:\n",
            "                  type: string\n",
            "                  descri...\n",
            "Score: 1.297 | # Авторизация\n",
            "\n",
            "> Для отправки авторизированных запросов необ...\n",
            "Score: 1.300 | headers: {}\n",
            "          x-apidog-name: Проверка привязанной ка...\n",
            "Score: 1.306 | x-run-in-apidog: https://app.apidog.com/web/project/1022226/...\n"
          ]
        }
      ],
      "source": [
        "# Look at similarity scores\n",
        "results_with_scores = vector_store.similarity_search_with_score(\"How do I authenticate?\", k=5)\n",
        "\n",
        "print(\"Similarity scores (lower = more similar):\\n\")\n",
        "for doc, score in results_with_scores:\n",
        "    print(f\"Score: {score:.3f} | {doc.page_content[:60]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "We4b97VxLWJD"
      },
      "source": [
        "## Benchmark Results\n",
        "\n",
        "Research comparing 18 RAG techniques found:\n",
        "\n",
        "| Technique | Accuracy |\n",
        "|-----------|----------|\n",
        "| **Simple RAG** | **0.30** |\n",
        "| Semantic Chunking | 0.20 |\n",
        "| HyDE | 0.50 |\n",
        "| Reranker | 0.70 |\n",
        "| Hybrid Search | 0.83 |\n",
        "| Adaptive RAG | 0.86 |\n",
        "\n",
        "Simple RAG only gets 30% right. We can do much better."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bo_mHRIwLWJE"
      },
      "source": [
        "## Summary\n",
        "\n",
        "**What we built:**\n",
        "- Loaded documents\n",
        "- Split into chunks\n",
        "- Created embeddings\n",
        "- Built a vector store\n",
        "- Combined retrieval + generation\n",
        "\n",
        "**Why it's not enough:**\n",
        "- Vector search misses exact matches\n",
        "- No relevance verification\n",
        "- No reranking of results\n",
        "- No hallucination prevention\n",
        "\n",
        "**Next notebook:** We'll fix all of these problems and build a production-ready system."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25ScJE2BLWJE",
        "outputId": "a3cc98c9-9377-4b2a-f92a-e5286d0a841a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Part 1 complete!\n",
            "Next: 02_production_rag.ipynb\n"
          ]
        }
      ],
      "source": [
        "print(\"Part 1 complete!\")\n",
        "print(\"Next: 02_production_rag.ipynb\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}