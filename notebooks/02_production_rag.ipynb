{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6sf4yLbQ4R1"
      },
      "source": [
        "# Part 2: Production RAG\n",
        "\n",
        "In this notebook, we'll build a production-ready RAG system with:\n",
        "\n",
        "1. **Hybrid Search** — Vector + Keyword search combined\n",
        "2. **Reranking** — Score and filter results\n",
        "3. **Relevance Check** — Verify we found useful info\n",
        "4. **Query Rewrite** — Retry with better phrasing\n",
        "5. **Grounding Check** — Prevent hallucinations\n",
        "\n",
        "This is how you go from 30% to 86% accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2a_VqAsQ4R3"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTbQZm4pQ4R4",
        "outputId": "e49be2e5-a232-4c29-80f1-bcf2bc6e3df8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/workshop\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/i33ym/workshop.git 2>/dev/null || echo \"Already cloned\"\n",
        "%cd workshop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1WMQIF_Q4R5",
        "outputId": "bf938307-517a-433d-94bb-80a4eb1e08c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/67.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.6/84.6 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m63.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.7/21.7 MB\u001b[0m \u001b[31m76.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m66.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m476.0/476.0 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m80.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.6/132.6 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.0/220.0 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m763.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m517.7/517.7 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.4/128.4 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m81.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m456.8/456.8 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "google-adk 1.20.0 requires opentelemetry-api<=1.37.0,>=1.37.0, but you have opentelemetry-api 1.39.1 which is incompatible.\n",
            "google-adk 1.20.0 requires opentelemetry-sdk<=1.37.0,>=1.37.0, but you have opentelemetry-sdk 1.39.1 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-exporter-otlp-proto-common==1.37.0, but you have opentelemetry-exporter-otlp-proto-common 1.39.1 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-proto==1.37.0, but you have opentelemetry-proto 1.39.1 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-sdk~=1.37.0, but you have opentelemetry-sdk 1.39.1 which is incompatible.\n",
            "opentelemetry-exporter-gcp-logging 1.11.0a0 requires opentelemetry-sdk<1.39.0,>=1.35.0, but you have opentelemetry-sdk 1.39.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q openai langchain langchain-openai langchain-community langchain-text-splitters chromadb rank-bm25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tgy4Dvi7Q4R6",
        "outputId": "09a4a93e-1552-43f8-c52b-295b37140a54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your OpenAI API key: ··········\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter your OpenAI API key: \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRmeuuq5Q4R7"
      },
      "source": [
        "## Load and Prepare Documents\n",
        "\n",
        "Same as Part 1 — load docs, split into chunks, create vector store."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tGM4_C3Q4R8",
        "outputId": "d430932d-ecbe-4689-bcb9-817badf7ef18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 731 chunks\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.document_loaders import DirectoryLoader, TextLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
        "from langchain_community.vectorstores import Chroma\n",
        "\n",
        "# Load\n",
        "loader = DirectoryLoader(\"docs/\", glob=\"**/*.md\", loader_cls=TextLoader)\n",
        "documents = loader.load()\n",
        "\n",
        "# Split\n",
        "splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=200,\n",
        "    separators=[\"\\n## \", \"\\n### \", \"\\n\\n\", \"\\n\", \" \"]\n",
        ")\n",
        "chunks = splitter.split_documents(documents)\n",
        "\n",
        "# Embed\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
        "vector_store = Chroma.from_documents(documents=chunks, embedding=embeddings)\n",
        "\n",
        "# LLM\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "\n",
        "print(f\"Loaded {len(chunks)} chunks\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dj9kHetQ4R9"
      },
      "source": [
        "## Stage 1: Hybrid Search\n",
        "\n",
        "**Problem:** Vector search finds similar meanings but misses exact terms.\n",
        "\n",
        "**Solution:** Combine vector search + keyword search (BM25).\n",
        "\n",
        "### What is BM25?\n",
        "BM25 is a keyword search algorithm. It finds documents containing the exact words you searched for."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "xDOuY7jPQ4R-"
      },
      "outputs": [],
      "source": [
        "from langchain_community.retrievers import BM25Retriever\n",
        "\n",
        "# Create BM25 retriever from same chunks\n",
        "bm25_retriever = BM25Retriever.from_documents(chunks)\n",
        "bm25_retriever.k = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XPlND0GQ4R-",
        "outputId": "6a424484-5d54-4332-8abe-b306e648bc96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: POST /api/payment\n",
            "\n",
            "=== Vector Search Results ===\n",
            "1. ## OpenAPI Specification\n",
            "\n",
            "```yaml\n",
            "openapi: 3.0.1\n",
            "info:\n",
            "  title: ''\n",
            "  description: ''\n",
            "  version: 1.0....\n",
            "\n",
            "2. ## OpenAPI Specification\n",
            "\n",
            "```yaml\n",
            "openapi: 3.0.1\n",
            "info:\n",
            "  title: ''\n",
            "  description: ''\n",
            "  version: 1.0....\n",
            "\n",
            "3. # paymentModel...\n",
            "\n",
            "=== BM25 (Keyword) Results ===\n",
            "1. Процесс проведения платежа с использованием холдирования происходит в 3 этапа:\n",
            "\n",
            "1. Создание холда с ...\n",
            "\n",
            "2. # Холдирование\n",
            "\n",
            "> Процесс проведения платежа с использованием холдирования происходит в 3 этапа:\n",
            "\n",
            "1....\n",
            "\n",
            "3. name:\n",
            "            type: string\n",
            "            description: Наименование товара/услуги\n",
            "          tin:\n",
            "  ...\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Compare: Vector vs BM25\n",
        "query = \"POST /api/payment\"\n",
        "\n",
        "print(f\"Query: {query}\\n\")\n",
        "\n",
        "print(\"=== Vector Search Results ===\")\n",
        "vector_results = vector_store.similarity_search(query, k=3)\n",
        "for i, doc in enumerate(vector_results):\n",
        "    print(f\"{i+1}. {doc.page_content[:100]}...\\n\")\n",
        "\n",
        "print(\"=== BM25 (Keyword) Results ===\")\n",
        "bm25_results = bm25_retriever.invoke(query)\n",
        "for i, doc in enumerate(bm25_results[:3]):\n",
        "    print(f\"{i+1}. {doc.page_content[:100]}...\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zTYfR1CQ4R_"
      },
      "source": [
        "### Reciprocal Rank Fusion (RRF)\n",
        "\n",
        "RRF combines results from multiple searches. Documents that appear in both searches rank higher."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "SRLx6rz2Q4R_"
      },
      "outputs": [],
      "source": [
        "def hybrid_search(query, k=5):\n",
        "    \"\"\"Combine vector search and BM25 using RRF.\"\"\"\n",
        "\n",
        "    # Get results from both methods\n",
        "    vector_results = vector_store.similarity_search(query, k=k)\n",
        "    bm25_results = bm25_retriever.invoke(query)[:k]\n",
        "\n",
        "    # Calculate RRF scores\n",
        "    rrf_scores = {}\n",
        "    k_constant = 60  # Standard RRF constant\n",
        "\n",
        "    for rank, doc in enumerate(vector_results):\n",
        "        doc_id = doc.page_content[:100]  # Use content as ID\n",
        "        rrf_scores[doc_id] = rrf_scores.get(doc_id, 0) + 1 / (k_constant + rank + 1)\n",
        "        rrf_scores[doc_id + \"_doc\"] = doc  # Store the document\n",
        "\n",
        "    for rank, doc in enumerate(bm25_results):\n",
        "        doc_id = doc.page_content[:100]\n",
        "        rrf_scores[doc_id] = rrf_scores.get(doc_id, 0) + 1 / (k_constant + rank + 1)\n",
        "        rrf_scores[doc_id + \"_doc\"] = doc\n",
        "\n",
        "    # Sort by score and return documents\n",
        "    sorted_ids = sorted(\n",
        "        [k for k in rrf_scores.keys() if not k.endswith(\"_doc\")],\n",
        "        key=lambda x: rrf_scores[x],\n",
        "        reverse=True\n",
        "    )\n",
        "\n",
        "    results = [rrf_scores[doc_id + \"_doc\"] for doc_id in sorted_ids[:k]]\n",
        "    scores = [rrf_scores[doc_id] for doc_id in sorted_ids[:k]]\n",
        "\n",
        "    return results, scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4qCTobk7Q4R_",
        "outputId": "6d0980b7-fe48-40b9-fb3a-1653d7567940"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: How do I authenticate API requests?\n",
            "\n",
            "=== Hybrid Search Results ===\n",
            "1. Score: 0.0328\n",
            "   # Авторизация\n",
            "\n",
            "> Для отправки авторизированных запросов необходимо получить токе...\n",
            "\n",
            "2. Score: 0.0161\n",
            "   headers: {}\n",
            "          x-apidog-name: Проверка привязанной карты\n",
            "      security: ...\n",
            "\n",
            "3. Score: 0.0161\n",
            "   # Introduction\n",
            "\n",
            "Платежный шлюз Multicard\n",
            "\n",
            "Документация API для партнеров и мерча...\n",
            "\n",
            "4. Score: 0.0159\n",
            "   x-run-in-apidog: https://app.apidog.com/web/project/1022226/apis/api-19729314-ru...\n",
            "\n",
            "5. Score: 0.0159\n",
            "   name:\n",
            "            type: string\n",
            "            description: Наименование товара/услу...\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Test hybrid search\n",
        "query = \"How do I authenticate API requests?\"\n",
        "\n",
        "results, scores = hybrid_search(query, k=5)\n",
        "\n",
        "print(f\"Query: {query}\\n\")\n",
        "print(\"=== Hybrid Search Results ===\")\n",
        "for i, (doc, score) in enumerate(zip(results, scores)):\n",
        "    print(f\"{i+1}. Score: {score:.4f}\")\n",
        "    print(f\"   {doc.page_content[:80]}...\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NipmTXUeQ4R_"
      },
      "source": [
        "## Stage 2: Reranking\n",
        "\n",
        "**Problem:** Search returns documents by similarity, not by how well they answer the question.\n",
        "\n",
        "**Solution:** Score each document's relevance to the question and keep only the best."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "R9RenjBiQ4SA"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "def rerank_documents(query, documents, top_n=3):\n",
        "    \"\"\"Score each document's relevance and return top results.\"\"\"\n",
        "\n",
        "    rerank_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
        "Rate how relevant this document is to answering the question.\n",
        "Reply with only a number from 0 to 10.\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Document: {document}\n",
        "\n",
        "Relevance score (0-10):\"\"\")\n",
        "\n",
        "    chain = rerank_prompt | llm | StrOutputParser()\n",
        "\n",
        "    scored_docs = []\n",
        "    for doc in documents:\n",
        "        try:\n",
        "            score_str = chain.invoke({\n",
        "                \"question\": query,\n",
        "                \"document\": doc.page_content[:500]\n",
        "            })\n",
        "            score = float(score_str.strip())\n",
        "        except:\n",
        "            score = 5.0\n",
        "\n",
        "        scored_docs.append((doc, score))\n",
        "\n",
        "    # Sort by score (highest first)\n",
        "    scored_docs.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    return scored_docs[:top_n]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBhgb1zyQ4SA",
        "outputId": "d78f2e3a-7069-4f18-956c-e2a4b37282f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: How do I create a payment?\n",
            "\n",
            "Reranking documents...\n",
            "\n",
            "=== Reranked Results ===\n",
            "1. Score: 8.0/10\n",
            "   # Создание платежа payme/click/uzum и прочие...\n",
            "\n",
            "2. Score: 8.0/10\n",
            "   # Создание платежа с передачей карточных данных...\n",
            "\n",
            "3. Score: 2.0/10\n",
            "   - field\n",
            "                            x-apidog-orders:\n",
            "                           ...\n",
            "\n",
            "\n",
            "Rerank scores: [8.0, 8.0, 2.0]\n"
          ]
        }
      ],
      "source": [
        "# Test reranking\n",
        "query = \"How do I create a payment?\"\n",
        "\n",
        "# First, get hybrid results\n",
        "hybrid_results, _ = hybrid_search(query, k=6)\n",
        "\n",
        "print(f\"Query: {query}\\n\")\n",
        "print(\"Reranking documents...\\n\")\n",
        "\n",
        "# Rerank them\n",
        "reranked = rerank_documents(query, hybrid_results, top_n=3)\n",
        "\n",
        "print(\"=== Reranked Results ===\")\n",
        "scores = []\n",
        "for i, (doc, score) in enumerate(reranked):\n",
        "    scores.append(score)\n",
        "    print(f\"{i+1}. Score: {score}/10\")\n",
        "    print(f\"   {doc.page_content[:80]}...\\n\")\n",
        "\n",
        "print(f\"\\nRerank scores: {scores}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6XvJMdEQ4SA"
      },
      "source": [
        "## Stage 3: Relevance Check\n",
        "\n",
        "**Problem:** Sometimes no documents are truly relevant. Simple RAG generates an answer anyway.\n",
        "\n",
        "**Solution:** Check if documents can actually answer the question before proceeding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "r1523REWQ4SA"
      },
      "outputs": [],
      "source": [
        "def check_relevance(query, documents):\n",
        "    \"\"\"Check if documents can answer the question.\"\"\"\n",
        "\n",
        "    context = \"\\n\\n\".join([doc.page_content[:300] for doc in documents])\n",
        "\n",
        "    relevance_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
        "Can this context answer the question? Reply only 'yes' or 'no'.\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Context: {context}\n",
        "\n",
        "Can this context answer the question?\"\"\")\n",
        "\n",
        "    chain = relevance_prompt | llm | StrOutputParser()\n",
        "    result = chain.invoke({\"question\": query, \"context\": context})\n",
        "\n",
        "    is_relevant = \"yes\" in result.lower()\n",
        "    return is_relevant, result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFFg_O2sQ4SB",
        "outputId": "3b36f3a0-b837-4586-f321-6660c61591f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: How do I authenticate?\n",
            "Is relevant: False (raw: no)\n"
          ]
        }
      ],
      "source": [
        "# Test with a relevant question\n",
        "query = \"How do I authenticate?\"\n",
        "docs, _ = hybrid_search(query, k=3)\n",
        "\n",
        "is_relevant, raw = check_relevance(query, docs)\n",
        "print(f\"Query: {query}\")\n",
        "print(f\"Is relevant: {is_relevant} (raw: {raw})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEnk3hvGQ4SB",
        "outputId": "cedb7d9e-b706-449c-edbe-fd71f5655c4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: How do I integrate with PayPal?\n",
            "Is relevant: False (raw: no)\n"
          ]
        }
      ],
      "source": [
        "# Test with an irrelevant question\n",
        "query = \"How do I integrate with PayPal?\"\n",
        "docs, _ = hybrid_search(query, k=3)\n",
        "\n",
        "is_relevant, raw = check_relevance(query, docs)\n",
        "print(f\"Query: {query}\")\n",
        "print(f\"Is relevant: {is_relevant} (raw: {raw})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "br3HW2_WQ4SB"
      },
      "source": [
        "## Stage 4: Query Rewrite\n",
        "\n",
        "**Problem:** Users don't always use the same terminology as the docs.\n",
        "\n",
        "**Solution:** If relevance check fails, rewrite the query and try again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "okwPizsbQ4SB"
      },
      "outputs": [],
      "source": [
        "def rewrite_query(query):\n",
        "    \"\"\"Rewrite query for better retrieval.\"\"\"\n",
        "\n",
        "    rewrite_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
        "Rewrite this question to be better for searching documentation.\n",
        "Use technical terms if applicable. Be specific.\n",
        "Reply with only the rewritten question.\n",
        "\n",
        "Original question: {question}\n",
        "\n",
        "Rewritten question:\"\"\")\n",
        "\n",
        "    chain = rewrite_prompt | llm | StrOutputParser()\n",
        "    return chain.invoke({\"question\": query})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZHUickQQ4SC",
        "outputId": "6b6f9661-14a0-452f-c686-ef495b4e1959"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  How do I log in?\n",
            "Rewritten: What are the steps to authenticate and establish a user session in the application?\n",
            "\n",
            "Original:  What happens when something goes wrong?\n",
            "Rewritten: What are the error handling mechanisms and failure response strategies in the system?\n",
            "\n",
            "Original:  How do I get money from a customer?\n",
            "Rewritten: What are the steps to process a customer payment in the payment gateway API?\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Test query rewrite\n",
        "test_queries = [\n",
        "    \"How do I log in?\",\n",
        "    \"What happens when something goes wrong?\",\n",
        "    \"How do I get money from a customer?\"\n",
        "]\n",
        "\n",
        "for q in test_queries:\n",
        "    rewritten = rewrite_query(q)\n",
        "    print(f\"Original:  {q}\")\n",
        "    print(f\"Rewritten: {rewritten}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzZA-Xx6Q4SC"
      },
      "source": [
        "## Stage 5: Grounding Check\n",
        "\n",
        "**Problem:** LLMs sometimes \"hallucinate\" — generate info not in the documents.\n",
        "\n",
        "**Solution:** Verify the answer is supported by the retrieved documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "EGCxiZ5RQ4SC"
      },
      "outputs": [],
      "source": [
        "def check_grounding(answer, documents):\n",
        "    \"\"\"Verify answer is supported by documents.\"\"\"\n",
        "\n",
        "    context = \"\\n\\n\".join([doc.page_content for doc in documents])\n",
        "\n",
        "    grounding_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
        "Is this answer fully supported by the context? Reply only 'yes' or 'no'.\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Answer:\n",
        "{answer}\n",
        "\n",
        "Is the answer fully supported?\"\"\")\n",
        "\n",
        "    chain = grounding_prompt | llm | StrOutputParser()\n",
        "    result = chain.invoke({\"context\": context, \"answer\": answer})\n",
        "\n",
        "    is_grounded = \"yes\" in result.lower()\n",
        "    return is_grounded, result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDr0ZeF8Q4SC"
      },
      "source": [
        "## Putting It All Together: Production RAG Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "TH_HI2YYQ4SD"
      },
      "outputs": [],
      "source": [
        "def generate_answer(query, documents):\n",
        "    \"\"\"Generate answer from documents.\"\"\"\n",
        "\n",
        "    context = \"\\n\\n---\\n\\n\".join([doc.page_content for doc in documents])\n",
        "\n",
        "    answer_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
        "Answer the question based only on the following context.\n",
        "If you can't find the answer, say \"I don't have information about this.\"\n",
        "Include code examples if relevant.\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Answer:\"\"\")\n",
        "\n",
        "    chain = answer_prompt | llm | StrOutputParser()\n",
        "    return chain.invoke({\"context\": context, \"question\": query})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "La6QlI8HQ4SD"
      },
      "outputs": [],
      "source": [
        "def production_rag(query, debug=False):\n",
        "    \"\"\"Full production RAG pipeline.\"\"\"\n",
        "\n",
        "    debug_info = {\"query\": query}\n",
        "\n",
        "    # Stage 1: Hybrid Search\n",
        "    if debug: print(\"[1] Hybrid Search...\")\n",
        "    docs, fusion_scores = hybrid_search(query, k=6)\n",
        "    debug_info[\"hybrid_results\"] = len(docs)\n",
        "\n",
        "    # Stage 2: Reranking\n",
        "    if debug: print(\"[2] Reranking...\")\n",
        "    reranked = rerank_documents(query, docs, top_n=3)\n",
        "    rerank_scores = [score for _, score in reranked]\n",
        "    top_docs = [doc for doc, _ in reranked]\n",
        "    debug_info[\"rerank_scores\"] = rerank_scores\n",
        "    if debug: print(f\"    Scores: {rerank_scores}\")\n",
        "\n",
        "    # Stage 3: Relevance Check\n",
        "    if debug: print(\"[3] Checking relevance...\")\n",
        "    is_relevant, _ = check_relevance(query, top_docs)\n",
        "    debug_info[\"is_relevant\"] = is_relevant\n",
        "\n",
        "    # Stage 4: Query Rewrite (if not relevant)\n",
        "    if not is_relevant:\n",
        "        if debug: print(\"[4] Not relevant, rewriting query...\")\n",
        "        new_query = rewrite_query(query)\n",
        "        debug_info[\"rewritten_query\"] = new_query\n",
        "        if debug: print(f\"    Rewritten: {new_query}\")\n",
        "\n",
        "        # Retry search\n",
        "        docs, _ = hybrid_search(new_query, k=6)\n",
        "        reranked = rerank_documents(new_query, docs, top_n=3)\n",
        "        top_docs = [doc for doc, _ in reranked]\n",
        "\n",
        "        # Check relevance again\n",
        "        is_relevant, _ = check_relevance(new_query, top_docs)\n",
        "        if not is_relevant:\n",
        "            if debug: print(\"    Still not relevant. Giving up.\")\n",
        "            return {\n",
        "                \"answer\": \"I don't have information about this topic in the documentation.\",\n",
        "                \"debug\": debug_info\n",
        "            }\n",
        "\n",
        "    if debug: print(f\"    Relevant: {is_relevant}\")\n",
        "\n",
        "    # Stage 5: Generate Answer\n",
        "    if debug: print(\"[5] Generating answer...\")\n",
        "    answer = generate_answer(query, top_docs)\n",
        "\n",
        "    # Stage 6: Grounding Check\n",
        "    if debug: print(\"[6] Checking grounding...\")\n",
        "    is_grounded, _ = check_grounding(answer, top_docs)\n",
        "    debug_info[\"is_grounded\"] = is_grounded\n",
        "    if debug: print(f\"    Grounded: {is_grounded}\")\n",
        "\n",
        "    # Get sources\n",
        "    sources = list(set([doc.metadata.get(\"source\", \"unknown\") for doc in top_docs]))\n",
        "\n",
        "    return {\n",
        "        \"answer\": answer,\n",
        "        \"sources\": sources,\n",
        "        \"is_grounded\": is_grounded,\n",
        "        \"debug\": debug_info\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nq_IiEu5Q4SD"
      },
      "source": [
        "## Test the Production Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jj2xF9QZQ4SD",
        "outputId": "ff1885e9-ffb5-4e70-f050-1e63b3da0a78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] Hybrid Search...\n",
            "[2] Reranking...\n",
            "    Scores: [9.0, 5.0, 3.0]\n",
            "[3] Checking relevance...\n",
            "    Relevant: True\n",
            "[5] Generating answer...\n",
            "[6] Checking grounding...\n",
            "    Grounded: True\n",
            "\n",
            "==================================================\n",
            "ANSWER:\n",
            "==================================================\n",
            "To authenticate API requests, you need to obtain a token by sending a POST request to the `/auth` endpoint with your application ID and secret. Once you have the token, include it in the header of your subsequent requests as follows:\n",
            "\n",
            "```http\n",
            "Authorization: Bearer {token}\n",
            "```\n",
            "\n",
            "Make sure to replace `{token}` with the actual token you received. The token will expire 24 hours after it is issued, after which you will receive a 401 Unauthorized error for any requests made with the expired token. It is recommended to cache the token for its duration instead of requesting a new one for each API call.\n"
          ]
        }
      ],
      "source": [
        "# Test with debug output\n",
        "result = production_rag(\"How do I authenticate API requests?\", debug=True)\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"ANSWER:\")\n",
        "print(\"=\"*50)\n",
        "print(result[\"answer\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7aNGMJzWQ4SD",
        "outputId": "55c887f3-3b2f-47d4-ea91-3a9ebe3d6b6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Q: How do I create a payment?\n",
            "----------------------------------------\n",
            "A: I don't have information about this topic in the documentation....\n",
            "Grounded: N/A\n",
            "\n",
            "Q: What error codes can the API return?\n",
            "----------------------------------------\n",
            "A: The API can return the error code \"400\" in cases of validation errors or when a confirmation request is made for a payment that has already been confirmed....\n",
            "Grounded: True\n",
            "\n",
            "Q: How do I integrate with Stripe?\n",
            "----------------------------------------\n",
            "A: I don't have information about this topic in the documentation....\n",
            "Grounded: N/A\n"
          ]
        }
      ],
      "source": [
        "# Test multiple questions\n",
        "test_questions = [\n",
        "    \"How do I create a payment?\",\n",
        "    \"What error codes can the API return?\",\n",
        "    \"How do I integrate with Stripe?\"  # Not in docs!\n",
        "]\n",
        "\n",
        "for q in test_questions:\n",
        "    print(f\"\\nQ: {q}\")\n",
        "    print(\"-\" * 40)\n",
        "    result = production_rag(q, debug=False)\n",
        "    print(f\"A: {result['answer'][:300]}...\")\n",
        "    print(f\"Grounded: {result.get('is_grounded', 'N/A')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SH1PwvaPQ4SE"
      },
      "source": [
        "## Compare: Simple vs Production RAG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPXwmrD1Q4SE",
        "outputId": "4498ef23-1e15-41e3-c69c-467db56b2a26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: How do I get a bearer token for authentication?\n",
            "\n",
            "=== Simple RAG ===\n",
            "To get a bearer token for authentication, you need to send a request to the API with your `application_id` and `secret`. The response will include the token, role, and expiry time. Here’s an example of how to request the token:\n",
            "\n",
            "```http\n",
            "POST /your/api/endpoint\n",
            "Content-Type: application/json\n",
            "\n",
            "{\n",
            "  \"ap\n",
            "\n",
            "=== Production RAG ===\n",
            "[1] Hybrid Search...\n",
            "[2] Reranking...\n",
            "    Scores: [7.0, 5.0, 3.0]\n",
            "[3] Checking relevance...\n",
            "[4] Not relevant, rewriting query...\n",
            "    Rewritten: What are the steps to obtain a bearer token for API authentication using OAuth 2.0?\n",
            "    Still not relevant. Giving up.\n",
            "\n",
            "Answer: I don't have information about this topic in the documentation.\n"
          ]
        }
      ],
      "source": [
        "def simple_rag(query):\n",
        "    \"\"\"The simple approach from Part 1.\"\"\"\n",
        "    docs = vector_store.similarity_search(query, k=3)\n",
        "    return generate_answer(query, docs)\n",
        "\n",
        "# Compare on a tricky question\n",
        "query = \"How do I get a bearer token for authentication?\"\n",
        "\n",
        "print(f\"Query: {query}\\n\")\n",
        "\n",
        "print(\"=== Simple RAG ===\")\n",
        "simple_answer = simple_rag(query)\n",
        "print(simple_answer[:300])\n",
        "\n",
        "print(\"\\n=== Production RAG ===\")\n",
        "prod_result = production_rag(query, debug=True)\n",
        "print(f\"\\nAnswer: {prod_result['answer'][:300]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DsUaL4wbQ4SE"
      },
      "source": [
        "## Summary\n",
        "\n",
        "**What we built:**\n",
        "\n",
        "| Stage | What it does | Why it matters |\n",
        "|-------|--------------|----------------|\n",
        "| Hybrid Search | Vector + BM25 | Catches both semantic and exact matches |\n",
        "| Reranking | Score relevance | Filters out noise |\n",
        "| Relevance Check | Verify we can answer | Prevents confident wrong answers |\n",
        "| Query Rewrite | Retry with better terms | Handles terminology mismatch |\n",
        "| Grounding Check | Verify answer is supported | Prevents hallucinations |\n",
        "\n",
        "**Benchmark improvement:**\n",
        "- Simple RAG: 0.30\n",
        "- Production RAG: 0.82-0.86\n",
        "\n",
        "**Next notebook:** Evaluation and debugging techniques."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bz14vN8eQ4SE",
        "outputId": "6f494ff3-7612-4eb4-eb2a-e60087df5fdc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Part 2 complete!\n",
            "Next: 03_evaluation.ipynb\n"
          ]
        }
      ],
      "source": [
        "print(\"Part 2 complete!\")\n",
        "print(\"Next: 03_evaluation.ipynb\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}